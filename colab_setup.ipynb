# -*- coding: utf-8 -*-
"""PredictX_Trinity_Training.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PredictXTrinityTrainingThisFileIsGenerated

# ðŸ¤– PredictX: The Trinity Training (Tier 7)
**Reinforcement Learning (PPO) + CNN Pattern Recognition + LSTM Trend Following**

This notebook sets up the environment to train the complete Trinity Ensemble for PredictX.

### 1. Setup Environment & Install Dependencies
"""

# Implementasi langkah-langkah setup manual
!pip install torch pandas numpy ccxt scikit-learn stable-baselines3 shimmy gymnasium matplotlib

import os
import sys

# Create directory structure
os.makedirs('backend/services', exist_ok=True)
os.makedirs('backend/models', exist_ok=True)
os.makedirs('backend/logs', exist_ok=True)

# Add backend to path
sys.path.append(os.path.abspath('backend'))

print("âœ… Environment Setup Complete")

"""### 2. Upload/Create Code Files
We will create the necessary Python files directly here.

#### 2.1 Backend Core Services
"""

# backend/services/data_service.py
%%writefile backend/services/data_service.py
import ccxt
import pandas as pd
from datetime import datetime
import time

def get_historical_data(symbol: str, period: str = "1mo", interval: str = "1h", limit: int = 1000) -> dict:
    print(f"Fetching data for {symbol} (Interval: {interval}) using CCXT/Binance...")
    try:
        exchange = ccxt.binance()
        if "-" in symbol: symbol = symbol.replace("-", "/")
        if "USD" in symbol and "USDT" not in symbol: symbol = symbol.replace("USD", "USDT")
        
        fetch_limit = min(limit, 1000)
        ohlcv = exchange.fetch_ohlcv(symbol, timeframe=interval, limit=fetch_limit)
        
        if not ohlcv: return {"error": f"No data found for symbol {symbol}"}

        df = pd.DataFrame(ohlcv, columns=['time', 'open', 'high', 'low', 'close', 'volume'])
        df['time'] = pd.to_datetime(df['time'], unit='ms').astype(str)
        
        return {"symbol": symbol, "count": len(df), "data": df.to_dict(orient="records")}
    except Exception as e:
        print(f"CCXT Error: {e}")
        return {"error": str(e)}

# backend/services/lstm_service.py
%%writefile backend/services/lstm_service.py
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import numpy as np

class TimeSeriesDataset(Dataset):
    def __init__(self, X, y):
        self.X = torch.tensor(X, dtype=torch.float32)
        self.y = torch.tensor(y, dtype=torch.float32)
    def __len__(self): return len(self.X)
    def __getitem__(self, idx): return self.X[idx], self.y[idx]

class LSTMModel(nn.Module):
    def __init__(self, input_size=1, hidden_size=64, num_layers=2, output_size=1):
        super(LSTMModel, self).__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)
    def forward(self, x):
        h0 = torch.zeros(2, x.size(0), 64).to(x.device) # Fixed num_layers=2, hidden=64 for simplicity
        c0 = torch.zeros(2, x.size(0), 64).to(x.device)
        out, _ = self.lstm(x, (h0, c0))
        out = self.fc(out[:, -1, :])
        return out

def train_model(model, train_loader, num_epochs=10, learning_rate=0.001):
    criterion = nn.MSELoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
    model.train()
    history = {'loss': []}
    for epoch in range(num_epochs):
        epoch_loss = 0
        for inputs, targets in train_loader:
            outputs = model(inputs)
            loss = criterion(outputs, targets.unsqueeze(1))
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            epoch_loss += loss.item()
        avg_loss = epoch_loss / len(train_loader)
        history['loss'].append(avg_loss)
        if (epoch+1) % 5 == 0: print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.6f}')
    return history

# backend/services/cnn_service.py
%%writefile backend/services/cnn_service.py
import torch
import torch.nn as nn
import torch.nn.functional as F

class CNNPatternModel(nn.Module):
    def __init__(self, sequence_length=20, input_features=4):
        super(CNNPatternModel, self).__init__()
        self.conv1 = nn.Conv1d(input_features, 32, 3, padding=1)
        self.bn1 = nn.BatchNorm1d(32)
        self.pool1 = nn.MaxPool1d(2)
        self.conv2 = nn.Conv1d(32, 64, 3, padding=1)
        self.bn2 = nn.BatchNorm1d(64)
        self.pool2 = nn.MaxPool1d(2)
        self.conv3 = nn.Conv1d(64, 128, 3, padding=1)
        self.bn3 = nn.BatchNorm1d(128)
        self.flat_size = 128 * 5
        self.fc1 = nn.Linear(self.flat_size, 64)
        self.dropout1 = nn.Dropout(0.3)
        self.fc2 = nn.Linear(64, 32)
        self.dropout2 = nn.Dropout(0.2)
        self.fc3 = nn.Linear(32, 1)

    def forward(self, x):
        x = self.pool1(F.relu(self.bn1(self.conv1(x))))
        x = self.pool2(F.relu(self.bn2(self.conv2(x))))
        x = F.relu(self.bn3(self.conv3(x)))
        x = x.view(-1, self.flat_size)
        x = F.relu(self.fc1(x))
        x = self.dropout1(x)
        x = F.relu(self.fc2(x))
        x = self.dropout2(x)
        x = torch.sigmoid(self.fc3(x))
        return x

def train_cnn_model(model, train_loader, num_epochs=30, learning_rate=0.001):
    criterion = nn.BCELoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
    model.train()
    history = {'loss': [], 'accuracy': []}
    for epoch in range(num_epochs):
        epoch_loss = 0; correct = 0; total = 0
        for batch_x, batch_y in train_loader:
            optimizer.zero_grad()
            outputs = model(batch_x)
            loss = criterion(outputs, batch_y)
            loss.backward()
            optimizer.step()
            epoch_loss += loss.item()
            predicted = (outputs > 0.5).float()
            total += batch_y.size(0)
            correct += (predicted == batch_y).sum().item()
        avg_loss = epoch_loss / len(train_loader)
        accuracy = 100 * correct / total
        history['loss'].append(avg_loss)
        history['accuracy'].append(accuracy)
        if (epoch + 1) % 5 == 0: print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, Acc: {accuracy:.2f}%")
    return history

# backend/services/chart_generator.py
%%writefile backend/services/chart_generator.py
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler

def generate_chart_windows(df, window_size=20):
    windows = []
    labels = []
    scaler = MinMaxScaler()
    ohlc_data = df[['open', 'high', 'low', 'close']].values
    
    for i in range(len(df) - window_size - 1):
        window = ohlc_data[i:i+window_size]
        window_normalized = scaler.fit_transform(window)
        next_close = df.iloc[i + window_size]['close']
        current_close = df.iloc[i + window_size - 1]['close']
        label = 1.0 if next_close > current_close else 0.0
        windows.append(window_normalized)
        labels.append(label)
    
    return np.array(windows), np.array(labels).reshape(-1, 1)

"""#### 2.2 AI Engine & RL Environment"""

# backend/ai_engine.py
# (Simpified version for training context)
%%writefile backend/ai_engine.py
import torch
import numpy as np
import pandas as pd
import joblib
import os
from sklearn.preprocessing import StandardScaler

def add_indicators(df):
    df['log_return'] = np.log(df['close'] / df['close'].shift(1))
    delta = df['close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / loss
    df['rsi'] = 100 - (100 / (1 + rs))
    df['ema_20'] = df['close'].ewm(span=20, adjust=False).mean()
    df['ema_diff'] = (df['close'] - df['ema_20']) / df['ema_20']
    df['ema_200'] = df['close'].ewm(span=200, adjust=False).mean()
    df.fillna(0, inplace=True)
    return df

# backend/rl_trading_env.py
%%writefile backend/rl_trading_env.py
import gymnasium as gym
from gymnasium import spaces
import numpy as np
import pandas as pd

class TradingEnv(gym.Env):
    def __init__(self, df, initial_balance=250000, fee_rate=0.001):
        super(TradingEnv, self).__init__()
        self.df = df
        self.initial_balance = initial_balance
        self.fee_rate = fee_rate
        
        # State: [Close_norm, RSI, EMA_Diff, LSTM_Prob (Placeholder), Position, Balance_norm, Leverage]
        self.observation_space = spaces.Box(low=np.array([0, 0, -1, 0, -1, 0, 0]), high=np.array([1, 100, 1, 1, 1, 10, 5]), dtype=np.float32)
        # Action: 0=Hold, 1=Buy1x, 2=Buy3x, 3=Buy5x, 4=Sell
        self.action_space = spaces.Discrete(5)
        self.reset()
    
    def reset(self, seed=None, options=None):
        super().reset(seed=seed)
        self.current_step = 60
        self.balance = self.initial_balance
        self.position = 0.0
        self.entry_price = 0.0
        self.leverage = 1
        self.trades = []
        return self._get_observation(), {}
    
    def _get_observation(self):
        row = self.df.iloc[self.current_step]
        recent_prices = self.df['close'].iloc[max(0, self.current_step-100):self.current_step+1]
        close_norm = (row['close'] - recent_prices.min()) / (recent_prices.max() - recent_prices.min() + 1e-8)
        return np.array([close_norm, row['rsi']/100, row['ema_diff'], 0.5, 1 if self.position > 0 else 0, self.balance/self.initial_balance, self.leverage/5.0], dtype=np.float32)
    
    def step(self, action):
        row = self.df.iloc[self.current_step]
        price = row['close']
        reward = 0
        done = False
        
        # Execute Action (Simplified)
        if action in [1, 2, 3] and self.position == 0:
            self.leverage = {1:1, 2:3, 3:5}[action]
            trade_amt = self.balance * 0.2 * self.leverage
            self.position = (trade_amt * (1 - self.fee_rate)) / price
            self.entry_price = price
            self.balance -= (trade_amt / self.leverage)
        elif action == 4 and self.position > 0:
            val = self.position * price
            profit = val - (self.entry_price * self.position)
            self.balance += (self.entry_price * self.position / self.leverage) + profit
            reward = (profit / (self.entry_price * self.position)) * 100
            self.position = 0; self.leverage = 1
            
        self.current_step += 1
        if self.current_step >= len(self.df)-1: done = True
        
        return self._get_observation(), reward, done, False, {}

"""### 3. Training Scripts

#### 3.1 Train CNN (Pattern Recognition)
"""

# backend/train_cnn.py
%%writefile backend/train_cnn.py
import sys
import os
sys.path.append(os.path.abspath('backend'))
import pandas as pd
import numpy as np
import torch
from torch.utils.data import DataLoader, TensorDataset
from services.cnn_service import CNNPatternModel, train_cnn_model
from services.chart_generator import generate_chart_windows
from services.data_service import get_historical_data
from ai_engine import add_indicators

def train_cnn(epochs=50):
    print("ðŸ§  Training CNN Pattern Model...")
    # Fetch Data
    raw_data = get_historical_data("BTC/USDT", period="2y", interval="1h", limit=1000)
    if "error" in raw_data: print(raw_data['error']); return
    
    df = pd.DataFrame(raw_data["data"])
    df = add_indicators(df)
    
    # Generate Windows
    windows, labels = generate_chart_windows(df, window_size=20)
    print(f"Generated {len(windows)} samples.")
    
    # Split
    split = int(len(windows)*0.8)
    train_x = torch.FloatTensor(windows[:split]).permute(0, 2, 1)
    train_y = torch.FloatTensor(labels[:split])
    
    train_dataset = TensorDataset(train_x, train_y)
    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
    
    model = CNNPatternModel()
    train_cnn_model(model, train_loader, num_epochs=epochs)
    
    torch.save(model.state_dict(), "backend/models/cnn_pattern_v1.pth")
    print("âœ… CNN Model Saved.")

if __name__ == "__main__":
    train_cnn()

#### 3.2 Train RL Agent (PPO)
"""

# backend/train_rl_agent.py
%%writefile backend/train_rl_agent.py
import sys
import os
sys.path.append(os.path.abspath('backend'))
import pandas as pd
from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import DummyVecEnv
from rl_trading_env import TradingEnv
from services.data_service import get_historical_data
from ai_engine import add_indicators

def train_rl(timesteps=50000):
    print("ðŸ¤– Training RL Agent (PPO)...")
    raw_data = get_historical_data("BTC/USDT", period="2y", interval="1h", limit=1000)
    df = pd.DataFrame(raw_data["data"])
    df = add_indicators(df)
    
    env = TradingEnv(df)
    env = DummyVecEnv([lambda: env])
    
    model = PPO("MlpPolicy", env, verbose=1, learning_rate=0.0003)
    model.learn(total_timesteps=timesteps)
    
    model.save("backend/models/ppo_agent")
    print("âœ… RL Model Saved.")

if __name__ == "__main__":
    train_rl()

"""### 4. Run Training
Execute the cells below to train the models.
"""

# Run CNN Training
!python backend/train_cnn.py

# Run RL Training
!python backend/train_rl_agent.py

"""### 5. Compress & Download Models
After training, run this to download your trained models (`cnn_pattern_v1.pth` and `ppo_agent.zip`).
"""

!zip -r trained_models.zip backend/models
from google.colab import files
files.download('trained_models.zip')
